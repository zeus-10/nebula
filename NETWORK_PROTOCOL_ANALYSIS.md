# Network Protocol & Workload Distribution

## Network Protocol

### What We're Using: **HTTP/1.1 over TCP**

**Stack:**
```
Application Layer:  HTTP/1.1 (REST API)
Transport Layer:    TCP (reliable, ordered)
Network Layer:     IP (routing)
Link Layer:        Ethernet/WiFi/Tailscale
```

**Why HTTP?**
- âœ… Standard REST API (FastAPI)
- âœ… Easy to implement
- âœ… Works over Tailscale VPN
- âœ… Supports streaming
- âœ… Can upgrade to HTTP/2 or HTTP/3 later

**TCP Characteristics:**
- âœ… Reliable (guaranteed delivery)
- âœ… Ordered (packets arrive in order)
- âœ… Connection-oriented (handshake, then data)
- âœ… Flow control (prevents overwhelming receiver)
- âœ… Error detection/correction

---

## Who Does the Heavy Lifting?

### The Reality: **Both Have Roles, But Different Work**

### Client Side (New Laptop) Responsibilities:

**Must Do (Unavoidable):**
1. **Read file from disk** â†’ Client's job (file is on client)
2. **Send data over network** â†’ Client's job (data originates here)
3. **Network transmission** â†’ Client's job (bytes must travel)

**Can Be Light:**
- âœ… Just read chunks and send (minimal processing)
- âœ… No buffering entire file
- âœ… No complex computation
- âœ… Simple streaming loop

**Client Workload:**
```
Read 10MB chunk from disk â†’ Send to server â†’ Repeat
Memory: ~10-50MB (one chunk at a time)
CPU: Minimal (just I/O)
Network: Sending data (unavoidable)
```

### Server Side (Old Laptop) Responsibilities:

**Does the Heavy Lifting:**
1. **Receives data** â†’ Server's job (listening)
2. **Validates/processes** â†’ Server's job (can be heavy)
3. **Stores to MinIO** â†’ Server's job (S3 operations)
4. **Saves metadata to DB** â†’ Server's job (database writes)
5. **Transcoding (later)** â†’ Server's job (CPU-intensive)

**Server Workload:**
```
Receive chunk â†’ Validate â†’ Stream to MinIO â†’ Update DB â†’ Repeat
Memory: ~10-50MB (one chunk at a time)
CPU: Can be heavy (validation, transcoding)
Storage: Writing to MinIO (I/O intensive)
```

---

## Data Flow Breakdown

### Upload Flow:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CLIENT (New Laptop) - Light Work                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Read 10MB chunk from disk (I/O)                     â”‚
â”‚ 2. Send chunk over HTTP/TCP (network)                  â”‚
â”‚ 3. Repeat for next chunk                                â”‚
â”‚                                                          â”‚
â”‚ Memory: ~10-50MB                                        â”‚
â”‚ CPU: Minimal                                            â”‚
â”‚ Network: Uploading (unavoidable)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“ HTTP/TCP over Tailscale
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SERVER (Old Laptop) - Heavy Lifting                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Receive chunk (network I/O)                          â”‚
â”‚ 2. Validate chunk (CPU - checksums, size, etc.)        â”‚
â”‚ 3. Stream to MinIO (storage I/O)                       â”‚
â”‚ 4. Update database (DB I/O)                           â”‚
â”‚ 5. Track progress (Redis)                              â”‚
â”‚ 6. [Later] Queue transcoding job (CPU-intensive)      â”‚
â”‚                                                          â”‚
â”‚ Memory: ~10-50MB                                        â”‚
â”‚ CPU: Can be heavy (validation, processing)             â”‚
â”‚ Storage: Writing to MinIO (I/O intensive)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Key Insight: **Client Sends, Server Processes**

### What Client MUST Do:
- **Read file** (file is on client's disk)
- **Send data** (data must travel over network)
- **Network transmission** (bytes must be sent)

**This is unavoidable** - the file is on the client, so the client must send it.

### What Server DOES (Heavy Lifting):
- **Receives and buffers** (handles network)
- **Validates** (checksums, file type, size limits)
- **Processes** (metadata extraction, thumbnails)
- **Stores** (MinIO operations, database writes)
- **Transcodes** (CPU-intensive video processing)

**This is where the heavy work happens** - server does all the processing.

---

## Network Protocol Details

### HTTP/1.1 Upload (Current Plan)

**Request:**
```http
POST /api/upload HTTP/1.1
Host: 100.x.y.z:8000
Content-Type: multipart/form-data
Content-Length: <chunk_size>

[Binary file data streamed in chunks]
```

**Characteristics:**
- âœ… Single TCP connection
- âœ… Streaming (chunks sent as available)
- âœ… Standard HTTP (works everywhere)
- âš ï¸ One connection (can be slow for very large files)

### HTTP/2 Upload (Future Option)

**Benefits:**
- âœ… Multiplexing (multiple streams on one connection)
- âœ… Better compression
- âœ… Server push (theoretical, not used for uploads)
- âœ… More efficient for large transfers

**Trade-off:**
- More complex implementation
- Requires HTTP/2 support in FastAPI/httpx

### HTTP/3 (QUIC) Upload (Future Option)

**Benefits:**
- âœ… Built on UDP (faster connection setup)
- âœ… Better for unreliable networks
- âœ… Multiplexing
- âœ… Built-in encryption

**Trade-off:**
- Very new (limited support)
- More complex

---

## Workload Distribution Examples

### Example 1: 1GB Video Upload

**Client (New Laptop):**
```
Work: Read 1GB file in 10MB chunks, send over network
Time: ~5-10 minutes (depends on network speed)
CPU: 5% (just I/O)
Memory: 50MB (one chunk)
Network: Uploading at ~2-20 Mbps
```

**Server (Old Laptop):**
```
Work: Receive chunks, validate, store to MinIO, save to DB
Time: Same as client (receiving in parallel)
CPU: 20-30% (validation, MinIO operations)
Memory: 50MB (one chunk)
Storage: Writing to MinIO at disk speed
```

**Heavy Lifting:** Server (validation, storage, database)

---

### Example 2: 10GB Video Upload with Transcoding

**Client (New Laptop):**
```
Work: Read 10GB file, send over network
Time: ~50-100 minutes
CPU: 5% (just I/O)
Memory: 50MB
Network: Uploading
```

**Server (Old Laptop):**
```
Work: Receive, validate, store, THEN transcode
Time: Upload (50-100 min) + Transcode (30-60 min)
CPU: 80-100% during transcoding (FFmpeg)
Memory: 500MB-1GB (during transcoding)
Storage: Reading from MinIO, writing transcoded version
```

**Heavy Lifting:** Server (especially transcoding - very CPU-intensive)

---

## Why Server Does Heavy Lifting

### Advantages:

1. **Client Stays Light**
   - Client laptop can do other work
   - No CPU-intensive processing on client
   - Client just reads and sends (simple)

2. **Server Has Resources**
   - Server is dedicated (old laptop in corner)
   - Can use all CPU/RAM for processing
   - Can run multiple workers (Celery)

3. **Centralized Processing**
   - All files processed in one place
   - Consistent processing environment
   - Easier to monitor and debug

4. **Scalability**
   - Can add more workers on server
   - Can distribute transcoding across workers
   - Client doesn't need to scale

---

## Network Protocol Choice: HTTP/1.1 over TCP

### Why This Works:

**TCP Provides:**
- âœ… Reliability (no lost packets)
- âœ… Ordering (chunks arrive in order)
- âœ… Flow control (server controls speed)
- âœ… Error correction (retransmits lost packets)

**HTTP Provides:**
- âœ… Standard API (REST)
- âœ… Streaming support
- âœ… Easy to implement
- âœ… Works over Tailscale

**HTTP/1.1 Limitations:**
- âš ï¸ One request per connection (for upload)
- âš ï¸ Head-of-line blocking (not an issue for single upload)

**For Our Use Case:**
- âœ… HTTP/1.1 is perfect
- âœ… Simple to implement
- âœ… Works reliably
- âœ… Can upgrade later if needed

---

## Data Transmission Reality

### The Unavoidable Truth:

**Data MUST travel from client to server:**
```
Client Disk â†’ Client Memory â†’ Network â†’ Server Memory â†’ Server Disk
```

**Client's Role:**
- Read from disk (fast - local SSD)
- Send over network (speed depends on connection)
- **This is unavoidable** - file is on client

**Server's Role:**
- Receive from network
- Process (heavy work happens here)
- Store (MinIO, database)

---

## Optimizations

### 1. Compression (Optional)

**Client:**
- Compress before sending (CPU work)
- Smaller payload (faster transfer)

**Trade-off:**
- Client does more work (compression)
- Server does less work (decompression)
- May not help for already-compressed files (videos)

**Recommendation:** Skip for now (videos are already compressed)

---

### 2. Chunked Transfer Encoding

**How it works:**
```
Client sends: Chunk 1 â†’ Chunk 2 â†’ Chunk 3 â†’ ...
Server receives: Chunk 1 â†’ Chunk 2 â†’ Chunk 3 â†’ ...
```

**Benefits:**
- âœ… No need to know file size upfront
- âœ… Can start processing while receiving
- âœ… Better memory usage

**HTTP/1.1 supports this natively** âœ…

---

### 3. Parallel Chunks (Advanced)

**Idea:** Send multiple chunks in parallel

**Reality:**
- HTTP/1.1: One connection = sequential chunks
- HTTP/2: Multiple streams = parallel chunks
- **For MVP:** Sequential is fine

**Trade-off:**
- More complex
- May not help (network is usually the bottleneck)

---

## Summary

### Network Protocol:
- **HTTP/1.1 over TCP** âœ…
- Standard, reliable, works over Tailscale
- Supports streaming natively

### Workload Distribution:

**Client (Light):**
- Reads file from disk
- Sends data over network
- **Unavoidable** - file is on client

**Server (Heavy Lifting):**
- Receives and validates
- Processes (metadata, thumbnails)
- Stores (MinIO, database)
- Transcodes (CPU-intensive)

### Key Insight:

**Client must send data** (file is on client's disk), but **server does all the heavy processing**. This is the optimal distribution:

- âœ… Client stays light (just I/O)
- âœ… Server does heavy work (processing, storage)
- âœ… Network is just transport (TCP handles reliability)

**For your use case:** This is perfect! Client is thin, server does the work. ğŸš€

---

## Implementation

**Client Code (Light):**
```python
# Just read and send - minimal work
with open(file_path, 'rb') as f:
    for chunk in read_chunks(f, chunk_size=10*1024*1024):
        send_chunk(chunk)  # Simple HTTP POST
```

**Server Code (Heavy):**
```python
# Receive, validate, process, store - heavy work
async def upload(file: UploadFile):
    async for chunk in file.stream():
        validate_chunk(chunk)      # CPU work
        await store_to_minio(chunk)  # I/O work
        update_progress()          # DB work
    extract_metadata()            # CPU work
    create_thumbnail()            # CPU work
    save_to_database()            # DB work
```

**Result:** Client is thin, server does the heavy lifting! âœ…


